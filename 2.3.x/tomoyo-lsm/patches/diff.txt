[PATCH v2] TOMOYO: Fix lockdep warning.

Currently TOMOYO holds SRCU lock upon open() and releases it upon close()
because list elements stored in the "struct tomoyo_io_buffer" instances are
accessed until close() is called. However, such SRCU usage causes lockdep to
complain about leaving the kernel with SRCU lock held.

Suppress the warning by holding/releasing SRCU upon each read()/write().
This patch does something similar to calling kfree() without calling
synchronize_srcu() by selectively deferring kfree() by keeping track of the
"struct tomoyo_io_buffer" instances.

Signed-off-by: Tetsuo Handa <penguin-kernel@I-love.SAKURA.ne.jp>

diff --git a/security/tomoyo/common.c b/security/tomoyo/common.c
index 7556315..3cabaf2 100644
--- a/security/tomoyo/common.c
+++ b/security/tomoyo/common.c
@@ -1785,8 +1785,6 @@ static void tomoyo_read_self_domain(struct tomoyo_io_buffer *head)
  * @file: Pointer to "struct file".
  *
  * Associates policy handler and returns 0 on success, -ENOMEM otherwise.
- *
- * Caller acquires tomoyo_read_lock().
  */
 int tomoyo_open_control(const u8 type, struct file *file)
 {
@@ -1880,8 +1878,6 @@ int tomoyo_open_control(const u8 type, struct file *file)
 			return -ENOMEM;
 		}
 	}
-	if (type != TOMOYO_QUERY)
-		head->reader_idx = tomoyo_read_lock();
 	file->private_data = head;
 	/*
 	 * Call the handler now if the file is
@@ -1900,6 +1896,7 @@ int tomoyo_open_control(const u8 type, struct file *file)
 	 */
 	else if (type == TOMOYO_QUERY)
 		atomic_inc(&tomoyo_query_observers);
+	tomoyo_notify_gc(head, true);
 	return 0;
 }
 
@@ -1928,14 +1925,13 @@ int tomoyo_poll_control(struct file *file, poll_table *wait)
  * @buffer_len: Size of @buffer.
  *
  * Returns bytes read on success, negative value otherwise.
- *
- * Caller holds tomoyo_read_lock().
  */
 int tomoyo_read_control(struct file *file, char __user *buffer,
 			const int buffer_len)
 {
 	int len;
 	struct tomoyo_io_buffer *head = file->private_data;
+	int idx;
 
 	if (!head->read)
 		return -ENOSYS;
@@ -1943,10 +1939,12 @@ int tomoyo_read_control(struct file *file, char __user *buffer,
 		return -EINTR;
 	head->read_user_buf = buffer;
 	head->read_user_buf_avail = buffer_len;
+	idx = tomoyo_read_lock();
 	if (tomoyo_flush(head))
 		/* Call the policy handler. */
 		head->read(head);
 	tomoyo_flush(head);
+	tomoyo_read_unlock(idx);
 	len = head->read_user_buf - buffer;
 	mutex_unlock(&head->io_sem);
 	return len;
@@ -1960,8 +1958,6 @@ int tomoyo_read_control(struct file *file, char __user *buffer,
  * @buffer_len: Size of @buffer.
  *
  * Returns @buffer_len on success, negative value otherwise.
- *
- * Caller holds tomoyo_read_lock().
  */
 int tomoyo_write_control(struct file *file, const char __user *buffer,
 			 const int buffer_len)
@@ -1970,17 +1966,22 @@ int tomoyo_write_control(struct file *file, const char __user *buffer,
 	int error = buffer_len;
 	int avail_len = buffer_len;
 	char *cp0 = head->write_buf;
+	int idx;
 
 	if (!head->write)
 		return -ENOSYS;
 	if (!access_ok(VERIFY_READ, buffer, buffer_len))
 		return -EFAULT;
+	if (mutex_lock_interruptible(&head->io_sem))
+		return -EINTR;
+	idx = tomoyo_read_lock();
 	/* Don't allow updating policies by non manager programs. */
 	if (head->write != tomoyo_write_pid &&
-	    head->write != tomoyo_write_domain && !tomoyo_manager())
+	    head->write != tomoyo_write_domain && !tomoyo_manager()) {
+		tomoyo_read_unlock(idx);
+		mutex_unlock(&head->io_sem);
 		return -EPERM;
-	if (mutex_lock_interruptible(&head->io_sem))
-		return -EINTR;
+	}
 	/* Read a line and dispatch it to the policy handler. */
 	while (avail_len > 0) {
 		char c;
@@ -2001,6 +2002,7 @@ int tomoyo_write_control(struct file *file, const char __user *buffer,
 		tomoyo_normalize_line(cp0);
 		head->write(head);
 	}
+	tomoyo_read_unlock(idx);
 	mutex_unlock(&head->io_sem);
 	return error;
 }
@@ -2011,13 +2013,11 @@ int tomoyo_write_control(struct file *file, const char __user *buffer,
  * @file: Pointer to "struct file".
  *
  * Releases memory and returns 0.
- *
- * Caller looses tomoyo_read_lock().
  */
 int tomoyo_close_control(struct file *file)
 {
 	struct tomoyo_io_buffer *head = file->private_data;
-	const bool is_write = !!head->write_buf;
+	file->private_data = NULL;
 
 	/*
 	 * If the file is /sys/kernel/security/tomoyo/query , decrement the
@@ -2025,18 +2025,7 @@ int tomoyo_close_control(struct file *file)
 	 */
 	if (head->type == TOMOYO_QUERY)
 		atomic_dec(&tomoyo_query_observers);
-	else
-		tomoyo_read_unlock(head->reader_idx);
-	/* Release memory used for policy I/O. */
-	kfree(head->read_buf);
-	head->read_buf = NULL;
-	kfree(head->write_buf);
-	head->write_buf = NULL;
-	kfree(head);
-	head = NULL;
-	file->private_data = NULL;
-	if (is_write)
-		tomoyo_run_gc();
+	tomoyo_notify_gc(head, false);
 	return 0;
 }
 
diff --git a/security/tomoyo/common.h b/security/tomoyo/common.h
index 7c66bd8..4794ed6 100644
--- a/security/tomoyo/common.h
+++ b/security/tomoyo/common.h
@@ -538,8 +538,6 @@ struct tomoyo_io_buffer {
 	int (*poll) (struct file *file, poll_table *wait);
 	/* Exclusive lock for this structure.   */
 	struct mutex io_sem;
-	/* Index returned by tomoyo_read_lock(). */
-	int reader_idx;
 	char __user *read_user_buf;
 	int read_user_buf_avail;
 	struct {
@@ -571,6 +569,10 @@ struct tomoyo_io_buffer {
 	int writebuf_size;
 	/* Type of this interface.              */
 	u8 type;
+	/* Users counter protected by tomoyo_io_buffer_list_lock. */
+	u8 users;
+	/* List for telling GC not to kfree() elements. */
+	struct list_head list;
 };
 
 /*
@@ -860,7 +862,7 @@ void tomoyo_print_ulong(char *buffer, const int buffer_len,
 void tomoyo_put_name_union(struct tomoyo_name_union *ptr);
 
 /* Run garbage collector. */
-void tomoyo_run_gc(void);
+void tomoyo_notify_gc(struct tomoyo_io_buffer *head, const bool is_register);
 
 void tomoyo_memory_free(void *ptr);
 
diff --git a/security/tomoyo/gc.c b/security/tomoyo/gc.c
index a877e4c..2a2f481 100644
--- a/security/tomoyo/gc.c
+++ b/security/tomoyo/gc.c
@@ -11,9 +11,128 @@
 #include <linux/kthread.h>
 #include <linux/slab.h>
 
+/* Size of an element. */
+static const u8 tomoyo_element_size[TOMOYO_MAX_POLICY] = {
+	[TOMOYO_ID_GROUP] = sizeof(struct tomoyo_group),
+	[TOMOYO_ID_PATH_GROUP] = sizeof(struct tomoyo_path_group),
+	[TOMOYO_ID_NUMBER_GROUP] = sizeof(struct tomoyo_number_group),
+	[TOMOYO_ID_TRANSITION_CONTROL] =
+	sizeof(struct tomoyo_transition_control),
+	[TOMOYO_ID_AGGREGATOR] = sizeof(struct tomoyo_aggregator),
+	[TOMOYO_ID_GLOBALLY_READABLE] = sizeof(struct tomoyo_readable_file),
+	[TOMOYO_ID_PATTERN] = sizeof(struct tomoyo_no_pattern),
+	[TOMOYO_ID_NO_REWRITE] = sizeof(struct tomoyo_no_rewrite),
+	[TOMOYO_ID_MANAGER] = sizeof(struct tomoyo_manager),
+	/* [TOMOYO_ID_NAME] = strlen("struct tomoyo_name"->entry.name) + 1, */
+	/* [TOMOYO_ID_ACL] =
+	   tomoyo_acl_size["struct tomoyo_acl_info"->type], */
+	[TOMOYO_ID_DOMAIN] = sizeof(struct tomoyo_domain_info),
+};
+
+/* Size of a domain ACL element. */
+static const u8 tomoyo_acl_size[] = {
+	[TOMOYO_TYPE_PATH_ACL] = sizeof(struct tomoyo_path_acl),
+	[TOMOYO_TYPE_PATH2_ACL] = sizeof(struct tomoyo_path2_acl),
+	[TOMOYO_TYPE_PATH_NUMBER_ACL] = sizeof(struct tomoyo_path_number_acl),
+	[TOMOYO_TYPE_MKDEV_ACL] = sizeof(struct tomoyo_mkdev_acl),
+	[TOMOYO_TYPE_MOUNT_ACL] = sizeof(struct tomoyo_mount_acl),
+};
+
+/* The list for "struct tomoyo_io_buffer". */
+static LIST_HEAD(tomoyo_io_buffer_list);
+/* Lock for protecting tomoyo_io_buffer_list. */
+static DEFINE_SPINLOCK(tomoyo_io_buffer_list_lock);
+
+/**
+ * tomoyo_struct_used_by_io_buffer - Check whether the list element is used by /sys/kernel/security/tomoyo/ users or not.
+ *
+ * @element: Pointer to "struct list_head".
+ *
+ * Returns true if @element is used by /sys/kernel/security/tomoyo/ users,
+ * false otherwise.
+ */
+static bool tomoyo_struct_used_by_io_buffer(const struct list_head *element)
+{
+	struct tomoyo_io_buffer *head;
+	bool in_use = false;
+	spin_lock(&tomoyo_io_buffer_list_lock);
+	list_for_each_entry(head, &tomoyo_io_buffer_list, list) {
+		head->users++;
+		spin_unlock(&tomoyo_io_buffer_list_lock);
+		if (mutex_lock_interruptible(&head->io_sem)) {
+			in_use = true;
+			goto out;
+		}
+		if (WARN_ONCE(head->r.domain == element,
+			      "***** %p is used by r.domain *****\n", element))
+			in_use = true;
+		if (WARN_ONCE(head->r.group == element,
+			      "***** %p is used by r.group *****\n", element))
+			in_use = true;
+		if (WARN_ONCE(head->r.acl == element,
+			      "***** %p is used by r.acl *****\n", element))
+			in_use = true;
+		if (WARN_ONCE(&head->write_var1->list == element,
+			      "***** %p is used by write_var1->list *****\n",
+			      element))
+			in_use = true;
+		mutex_unlock(&head->io_sem);
+out:
+		spin_lock(&tomoyo_io_buffer_list_lock);
+		head->users--;
+		if (in_use)
+			break;
+	}
+	spin_unlock(&tomoyo_io_buffer_list_lock);
+	return in_use;
+}
+
+/**
+ * tomoyo_name_used_by_io_buffer - Check whether the string is used by /sys/kernel/security/tomoyo/ users or not.
+ *
+ * @string: String to check.
+ * @size:   Memory allocated for @string .
+ *
+ * Returns true if @string is used by /sys/kernel/security/tomoyo/ users,
+ * false otherwise.
+ */
+static bool tomoyo_name_used_by_io_buffer(const char *string, const int size)
+{
+	struct tomoyo_io_buffer *head;
+	bool in_use = false;
+	spin_lock(&tomoyo_io_buffer_list_lock);
+	list_for_each_entry(head, &tomoyo_io_buffer_list, list) {
+		int i;
+		head->users++;
+		spin_unlock(&tomoyo_io_buffer_list_lock);
+		if (mutex_lock_interruptible(&head->io_sem)) {
+			in_use = true;
+			goto out;
+		}
+		for (i = 0; i < TOMOYO_MAX_IO_READ_QUEUE; i++) {
+			const char *w = head->r.w[i];
+			if (w < string || w > string + size)
+				continue;
+			WARN_ONCE(1, "***** %s is used by w[%u] *****\n",
+				  string, i);
+			in_use = true;
+			break;
+		}
+		mutex_unlock(&head->io_sem);
+out:
+		spin_lock(&tomoyo_io_buffer_list_lock);
+		head->users--;
+		if (in_use)
+			break;
+	}
+	spin_unlock(&tomoyo_io_buffer_list_lock);
+	return in_use;
+}
+
 struct tomoyo_gc {
 	struct list_head list;
 	int type;
+	int size;
 	struct list_head *element;
 };
 static LIST_HEAD(tomoyo_gc_queue);
@@ -26,12 +145,48 @@ static bool tomoyo_add_to_gc(const int type, struct list_head *element)
 	if (!entry)
 		return false;
 	entry->type = type;
+	if (type == TOMOYO_ID_ACL)
+		entry->size =
+			tomoyo_acl_size[container_of(element,
+						     typeof(struct
+							    tomoyo_acl_info),
+						     list)->type];
+	else if (type == TOMOYO_ID_NAME)
+		entry->size = strlen(container_of(element,
+						  typeof(struct tomoyo_name),
+						  list)->entry.name) + 1;
+	else
+		entry->size = tomoyo_element_size[type];
 	entry->element = element;
 	list_add(&entry->list, &tomoyo_gc_queue);
 	list_del_rcu(element);
 	return true;
 }
 
+/**
+ * tomoyo_element_linked_by_gc - Validate next element of an entry.
+ *
+ * @element: Pointer to an element.
+ * @size:    Size of @element in byte.
+ *
+ * Returns true if @element is linked by other elements in the garbage
+ * collector's queue, false otherwise.
+ */
+static bool tomoyo_element_linked_by_gc(const u8 *element, const int size)
+{
+	struct tomoyo_gc *p;
+	list_for_each_entry(p, &tomoyo_gc_queue, list) {
+		const u8 *ptr = (const u8 *) p->element->next;
+		if (ptr < element || element + size < ptr)
+			continue;
+		WARN_ONCE(element < ptr && ptr < element + size,
+			  "***** %p < %p < %p *****\n", element, ptr,
+			  element + size);
+		return true;
+	}
+	return false;
+}
+
 static void tomoyo_del_allow_read(struct list_head *element)
 {
 	struct tomoyo_readable_file *ptr =
@@ -127,42 +282,17 @@ static void tomoyo_del_acl(struct list_head *element)
 	}
 }
 
-static bool tomoyo_del_domain(struct list_head *element)
+static void tomoyo_del_domain(struct list_head *element)
 {
 	struct tomoyo_domain_info *domain =
 		container_of(element, typeof(*domain), list);
 	struct tomoyo_acl_info *acl;
 	struct tomoyo_acl_info *tmp;
-	/*
-	 * Since we don't protect whole execve() operation using SRCU,
-	 * we need to recheck domain->users at this point.
-	 *
-	 * (1) Reader starts SRCU section upon execve().
-	 * (2) Reader traverses tomoyo_domain_list and finds this domain.
-	 * (3) Writer marks this domain as deleted.
-	 * (4) Garbage collector removes this domain from tomoyo_domain_list
-	 *     because this domain is marked as deleted and used by nobody.
-	 * (5) Reader saves reference to this domain into
-	 *     "struct linux_binprm"->cred->security .
-	 * (6) Reader finishes SRCU section, although execve() operation has
-	 *     not finished yet.
-	 * (7) Garbage collector waits for SRCU synchronization.
-	 * (8) Garbage collector kfree() this domain because this domain is
-	 *     used by nobody.
-	 * (9) Reader finishes execve() operation and restores this domain from
-	 *     "struct linux_binprm"->cred->security.
-	 *
-	 * By updating domain->users at (5), we can solve this race problem
-	 * by rechecking domain->users at (8).
-	 */
-	if (atomic_read(&domain->users))
-		return false;
 	list_for_each_entry_safe(acl, tmp, &domain->acl_info_list, list) {
 		tomoyo_del_acl(&acl->list);
 		tomoyo_memory_free(acl);
 	}
 	tomoyo_put_name(domain->domainname);
-	return true;
 }
 
 
@@ -283,6 +413,30 @@ static void tomoyo_kfree_entry(void)
 
 	list_for_each_entry_safe(p, tmp, &tomoyo_gc_queue, list) {
 		struct list_head *element = p->element;
+		/*
+		 * list_del_rcu() in tomoyo_add_to_gc() guarantees that the
+		 * list element became no longer reachable from the list which
+		 * the element was originally on (e.g. tomoyo_domain_list).
+		 * Also, synchronize_srcu() in tomoyo_gc_thread() guarantees
+		 * that the list element became no longer referenced by syscall
+		 * users.
+		 *
+		 * However, there are three users which may still be using the
+		 * list element. We need to defer until all of these users
+		 * forget the list element.
+		 *
+		 * Firstly, defer until "struct tomoyo_io_buffer"->r.{domain,
+		 * group,acl} and "struct tomoyo_io_buffer"->write_var1 forget
+		 * the list element.
+		 */
+		if (tomoyo_struct_used_by_io_buffer(element))
+			continue;
+		/*
+		 * Secondly, defer until all other elements in the
+		 * tomoyo_gc_queue list forget the list element.
+		 */
+		if (tomoyo_element_linked_by_gc((const u8 *) element, p->size))
+			continue;
 		switch (p->type) {
 		case TOMOYO_ID_TRANSITION_CONTROL:
 			tomoyo_del_transition_control(element);
@@ -303,14 +457,37 @@ static void tomoyo_kfree_entry(void)
 			tomoyo_del_manager(element);
 			break;
 		case TOMOYO_ID_NAME:
+			/*
+			 * Thirdly, defer until all "struct tomoyo_io_buffer"
+			 * ->r.w[] forget the list element.
+			 */
+			{
+				const char *name =
+					container_of(element,
+						     const struct tomoyo_name,
+						     list)->entry.name;
+				if (tomoyo_name_used_by_io_buffer(name,
+								  p->size))
+					continue;
+			}
 			tomoyo_del_name(element);
 			break;
 		case TOMOYO_ID_ACL:
 			tomoyo_del_acl(element);
 			break;
 		case TOMOYO_ID_DOMAIN:
-			if (!tomoyo_del_domain(element))
-				continue;
+			/*
+			 * Thirdly, defer until all "struct cred"->security
+			 * forget the list element.
+			 */
+			{
+				struct tomoyo_domain_info *domain =
+					container_of(element, typeof(*domain),
+						     list);
+				if (atomic_read(&domain->users))
+					continue;
+			}
+			tomoyo_del_domain(element);
 			break;
 		case TOMOYO_ID_PATH_GROUP:
 			tomoyo_del_path_group(element);
@@ -345,10 +522,36 @@ static int tomoyo_gc_thread(void *unused)
 	do_exit(0);
 }
 
-void tomoyo_run_gc(void)
+/**
+ * tomoyo_notify_gc - Register/unregister /sys/kernel/security/tomoyo/ users.
+ *
+ * @head:        Pointer to "struct tomoyo_io_buffer".
+ * @is_register: True if register, false if unregister.
+ *
+ * Returns nothing.
+ */
+void tomoyo_notify_gc(struct tomoyo_io_buffer *head, const bool is_register)
 {
-	struct task_struct *task = kthread_create(tomoyo_gc_thread, NULL,
-						  "GC for TOMOYO");
-	if (!IS_ERR(task))
-		wake_up_process(task);
+	bool is_write = false;
+	spin_lock(&tomoyo_io_buffer_list_lock);
+	if (is_register) {
+		head->users = 1;
+		list_add(&head->list, &tomoyo_io_buffer_list);
+	} else {
+		is_write = head->write_buf != NULL;
+		if (!--head->users) {
+			list_del(&head->list);
+			kfree(head->read_buf);
+			kfree(head->write_buf);
+			kfree(head);
+		}
+	}
+	spin_unlock(&tomoyo_io_buffer_list_lock);
+	if (is_write) {
+		struct task_struct *task =
+			kthread_create(tomoyo_gc_thread, NULL,
+				       "GC for TOMOYO");
+		if (!IS_ERR(task))
+			wake_up_process(task);
+	}
 }
